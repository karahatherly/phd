\chapter{Temporal Isolation}
\label{chap:scheduling}

Mixed-criticality systems at their core require isolation: isolation as strong as that provided by phyiscally isolated systems, meaning if one system fails it cannot effect another system.
Isolation can be divided into two categories: physical and temporal.
Physical isolation refers to the isoaltion of physical resources: devices and memory, which can be achieved easily in modern \glspl{SoC} equipped with \glspl{MMU} and I/O \glspl{MMU}.
Temporal isolation is more complicated: this refers to isolation of temporal resources.

We look to the real-time theory, which has developed many theories based on time-sensitive results.
The difference however, is that much research in the real-time space has an implicit assumption of trust: the scheduling algoritms and locking protocols presented in \Cref{sec:real-time-theory} assume tasks will not overrun their execution requirement. 

Most existing real-time systems run either one application, or multiple applications of the same criticality, meaning each application that is running is certified to the same level.
This means that all applications are trusted: trusted to not crash, and trusted to not overrun their deadlines.
If one application does overrun its deadline or use more processing time that specified by its \gls{WCET}, other applications will miss their deadlines.

A system is said to provide \emph{temporal isolation} if temporal faults in one task cannot cause temporal faults in another, independent task.
Neither scheduling approach discussed so far provides temporal isolation, although both can be adapted to do so.

Temporal isolation requires tasks to specify their expected, or permitted temporal behaviour.
This can be done by specifying a processor share, as in proportional share schedulers, or by using the period and execution requirement of the sporadic task model as an upper bound on task processor utilisation.

The issue of trust in real-time literature has not been greatly address: real time tasks are often assumed to perform correctly and safely.
However, much research has looked into the scheduling of aperiodic tasks, which by definition do cannot be trusted to follow a specific schedule, or abide by their estimated interarrival time.
Consequently we look to scheduling methods for aperiodic tasks in order to implement temporal isolation.

\subsection{Proportional share schedulers}

Proportional share schedulers provide temporal isolation, as long as the system is not overloaded.
Recall that fairness is not a central property of scheduling in an \gls{RTOS}. There is, however, a class of real-time scheduling algorithms that attempt to provide fairness and also satisfy temporal constraints.
These are referred to as \emph{proportional share} algorithms, which allocate time to tasks in discrete sized quanta.Tasks are assigned weights according to their rate.
Task weights determine the share of time for which each job has access to a resource.

While proportional share algorithms are applied to many different scheduling problems, they apply well to real-time scheduling on one or more processors.

Unlike other approaches to real-time scheduling, proportional share schedulers have the explicit property of guaranteeing a rate of progress for all tasks in the system.
Some criticise this approach for over-constraining the system and introducing overhead-related capacity loss due to a heightened number of context switches~\citep{Abeni_Buttazzo_2004}.

\citet{Baruah_CPV_1996} introduced the property \emph{proportionate fairness} or \emph{Pfair} as a strong fairness property for proportionate share scheduling algorithms.
For a schedule to be Pfair, then at every time $t$ a task $T$ with weight $T_{w}$ must have been scheduled either $\lceil T_{w} . t \rceil$ or $\lfloor T_{w}.t \rfloor $ times.
\emph{Early-Release fair} or ERfair~\citep{Anderson_Srinivasan_2004} is an extension of the Pfair property that allows tasks to execute before their Pfair window, which can allow for better response times.

Pfair scheduling algorithms break jobs into sub-jobs that match the length of a quantum.
Real-time and non-real time tasks are treated similarly.
When overload conditions exist, the rate is slowed for all tasks.

Pfair scheduling algorithms are good theoretically but do not perform well in practice.
Since scheduling decisions can only be made at quantised intervals, scheduling is less precise in proportionate fair systems.
This problem can be exacerbated by critical sections, which may last longer than a single quantum.
\citet{Stoica_AKBGP_96} propose defining arbitrary quanta sizes based on maximum critical section size, however quanta size decreases the accuracy of the scheduler.
Additionally, it may not be possible to have a priori knowledge of critical section size, especially in a soft real-time systems where it is not worth conducting \gls{WCET} analysis or execution time is dependant on exterior factors, such as network behaviour.

One early uniprocessor Pfair scheduling algorithm is earliest eligible deadline first, presented in \citet{Stoica_AKBGP_96}.
PD$^{2}$~\citep{Srinivasan_Anderson_2006} is a more recent Pfair/ERfair scheduling algorithm that is theoretically optimal for multiprocessors under \gls{HRT} constraints, although only under the assumption that process preemption and migration are free.

Recall that temporal isolation means that tasks should not be able to interfere with the temporal behaviour of other tasks in the system.
Proportionate fair systems provide temporal isolation as part of their fairness property, unless the system is overloaded, at which point the rate of all tasks will degrade.

\subsection{Isolation with EDF schedulers}

Temporal isolation in \gls{EDF} scheduling has been explored throughly in the real-time discipline.
We outline the most dominant approaches in this section.

\paragraph{Robust earliest deadline scheduling}
One very early approach to mixed-criticality scheduling attempts to extend \gls{EDF} to allow overload conditions to be handled with respect to a value. Robust earliest deadline scheduling~\citep{Buttazzo_Stankovic_1993} assigns a value to each task set.
The algorithm will drop jobs from low-value tasks under overload, although they can be scheduled again later once the system returns to non-overload conditions.
The algorithm is optimal, however this is only the case if scheduler overhead is excluded.
Since the algorithm is has O($n$) complexity in the number of tasks, the authors recommend using a dedicated scheduling processor such that overhead will not effect the timing behaviour -- but this is not suitable for embedded systems, where the goal is to minimise the number of processors, not increase them.

\paragraph{\gls{CBS}} \citet{Abeni_Buttazzo_2004} introduce a technique for scheduling \gls{HRT} and \gls{SRT} tasks and providing temporal isolation.
\gls{HRT} tasks are scheduled using an \gls{EDF} scheduler, but \gls{SRT} tasks are treated differently as \gls{EDF} does not handle overload.
Instead, a \gls{CBS} is assigned to each \gls{SRT} task.
Each \gls{CBS} has a bandwidth assigned to it, and breaks down \gls{SRT} jobs into sub-jobs such that the utilisation rate of the task does not exceed the assigned bandwidth.
Any sub-job that will cause the bandwidth to be exceeded is postponed, but still executed.

\gls{CBS} stands out from previous server based approaches~\citep{Spuri_Buttazzo_1996, Ghazalie_B_1995, Spuri_Buttazzo_1994, Deng_Liu_1997} as it does not require a \gls{WCET} or a minimum bound on job inter-arrival time, making it much more suitable for \gls{SRT} tasks.
Implementation wise, \gls{CBS} has fewer hardware overheads than Pfair schedulers.

Many extensions exist to \gls{CBS} to improve functionality.
\citet{Kato_IR_2011} extend \gls{CBS} to implement \emph{slack donation}, where any unused bandwidth is given to other jobs.
In ~\citep{Craciunas_KPRS_2012}, \gls{CBS} is extended such that bandwidths are variable at run-time.
\citet{Lamastra_LA_01} introduce bandwidth inheritance across CBS servers applied to different resources, providing temporal isolation for additional resources other than processing time.

\paragraph{\gls{RBED}} schedulers explicitly separate the resource allocation and dispatching (choosing which thread to run) in order to provide flexibility in timeliness requirements supported by the scheduler.
  \Gls{RBED} ~\citep{Brandt_BLB_03} is an algorithm that implements such a scheduler.

In \gls{RBED}, tasks are considered as either \gls{HRT}, \gls{SRT}, \gls{NRT} or rate-based.
Tasks are modelled using an extension of the periodic task model, allowing any job of a task to have a different period.
If rate-based or \gls{HRT} tasks cannot be scheduled at their desired rate they are rejected.
\gls{SRT} tasks are given their rate if possible with the option to provide a quality of service specification.
Processor time reservations can be used to make sure \gls{NRT} tasks are allowed some execution time.
Otherwise they are allocated slack time unused by SRT and HRT tasks.
Either way, \gls{NRT} tasks are scheduled by assigning them a rate that reflects how they would be scheduled in a standard, fair, quantum-based scheduler.
Based on the rates used, \gls{RBED} breaks tasks down and feeds them to an \gls{EDF} scheduler to manage processing time.
Rates are enforced using a one-shot timer to stop tasks that exceed their {\gls{WCET}}.
As tasks enter and leave the system, the rates of \gls{SRT} tasks will change.
Slack time that occurs as a result of tasks completing before their deadlines is only donated to \gls{NRT} tasks, although the authors note that extensions should be able to donate slack to \gls{SRT} tasks as well.

\Gls{RBED} is similar to the concept of CBS, however it deals with separate types of real-time tasks more explicitly.

\subsection{Isolation with FP schedulers}
\label{background:fp-isolation}

While \gls{CBS} and \gls{RBED} provide temporal isolation for \gls{EDF} scheduling, we will now examine methods for temporal isolation in fixed-priority systems, whilst maintaining compatibility with rate-monotonic schedulability tests.
Like \gls{CBS}, tasks are constrained by encapsulating one or more tasks in a server which prevents the task(s) from overruning their assigned scheduling parameters.
Many solutions for scheduling aperiodic tasks

\paragraph{Polling servers}\label{p:polling-servers}~\citep{Lehoczky_LS_87} wake every period, checks if there are any pending tasks and runs them for maximum their budget time. If there is no task to run, the polling server will go back to sleep. That is, at time $t_{i}$, if there are no tasks ready to execute, the server will sleep until $t_{i+1}$. This has the limitation task latency is a function of the period $T$.

\paragraph{Deferrable Servers} Unlike polling servers, \emph{deferrable servers}\citep{Lehoczky_LS_87, Strosnider_LS_1995} preserve any unused budget across periods, although the budget can never be exceeded.
This removes the latency problems with polling servers, but unfortunately breaks rate-monotonic schedulability analysis, as this policay can result in servers executing back-to-back and using more than thier scheduling bandwidth for any specific occurence of the period.
This occurs as deferrable servers replenish the budget to full at the start of each period, and the budget can be used at any point during a tasks execution.
The problem occurs when a task wakes at $t_{i} - C$, consumes its whole budget, however then has its budget replenished at $t_{i+1}$.
This means for the time between $t_{i} - C$ and $t_{i+1} + C$, the task has exceeded more than its utilisation ($\frac{C}{T}.$
As a result deadline misses can be caused in other tasks violating temporal isolation.

\paragraph{Sporadic servers}~\citep{Sprunt_SL_89a}\label{p:sporadic} address the problems of deferrable servers by scheduling multiple replenishment times, in order to preserve the property that $\forall t_{i}, t_{j} U \leq \frac{C}{T}$, known as the \emph{sliding window} constraint, which is the condition that deferrable servers violate.
Each time a task is preempted, or blocks, a replenishment is set for current time + $T$, for the amount consumed.
When no replenishments are available, sporadic servers have their priority decreased below any real-time task. 
The priority is restored once a replenishment is available.
While this addresses the problems of deferrable servers, the implementation is problematic as the number of times a thread is preempted or blocked is potentially unbounded.
It is also subject to capacity loss as tasks that use very small chunks of budget at a time increase the interrupt load.
The bigger the bound on replenishments the less accurate the sporadic server, but the more memory used resulting in performance degredations.

\paragraph{Priority exchange servers}~\citep{Sprunt_SL_89a} swap the priority of an inactive aperiodic task with a periodic task, such that server capacity is not lost but used at a lower priority.
Implementations of priority exchange require control and access to priorities across an entire system.

%TODO slack defined?
\paragraph{Slack stealing}~\citep{Ramos_Thuel_Lehoczky_93} is an approach that runs a scheduling task at the lowest priority and tracks the amount of slack per task in the system.
As aperiodic tasks arrive, the slack stealer calculates whether they can be scheduled or not based on the slack in the system and current load of periodic tasks.
This method does not provide guarantees at all for the aperiodic tasks, unless a certain bound is placed on the execution of periodic tasks.

% TODO table comparing methods
\section{Resource sharing}

Like the scheduling algorithms, the locking protocols presented in \Cref{sec:resource-sharing-theory} do not work if tasks are untrusted: in all of the protocols, if a task does not voluntarily release the resource, all other tasks sharing that resource will be blocked.

One of our goals is to allow tasks of different criticality to share resources. 
While the resource itself must be at the highest criticality of systems using it, this relationship need not be symmetric; low criticality systems should be able to use high criticality resources.

In this section we explore how resource reservations and real-time locking protocols interact, and asses their suitability for mixed criticality systems.
As introduced in \cref{sec:resource-kernels}, when combining locking protocols and reservations one must consider prioritisation, charging and enforcement.

Prioritisation, or what priority a task uses while accessing a resource, can be decided by any of the existing protocols: \gls{PCP}, \gls{HLP} or \gls{PIP}. 
Charging the reservation, and which reservation to charge, is more interesting. 
\citet{deNiz_LSR_2001} describe the possible mappings between reservations and resources consuming those reservations, and comes down to the following choices:

\begin{description}
\item[Bandwidth inheritance] Tasks using the resource run on their own reservation.
If that reservation expires and their are other pending tasks, the task runs on the reservations of the pending tasks. 
\item[Reservation for the resource] Shared resources have their own reservation, which tasks use.
This reservation must be enough for all tasks to complete their request. 
Once again, if tasks are untrusted no temporal isolation is provided 
\item[Multi-reserve resources] Shared resources have multiple reservations, and the resource actively switches between them depending on which task it is servicing. 
\end{description} 

Of most relevant to mixed-criticality systems, where tasks cannot be guaranteed to release a resource, is the enforcement mechanism.
Many protocols rely on tasks being trusted with \emph{a priori} knowledge of a tasks resource usage. 
However, in systems where tasks may not be trusted (either due to security, ceritification level, or potential incorrectness) such \emph{a priori} knowledge is unavailable. 

We address this topic further in the next chapter, when we evaluate survey existing operating systems.

\section{Asymmetric Protection} 
% TODO more more more

Temporal isolation in mixed-criticality systems can result in \emph{criticality inversion}, where high criticality tasks miss their deadlines due to lower criticality tasks.
Rather than temporal isolation, mixed-criticality systems require \emph{asymmetric protection}, where deadline misses of low-criticality tasks caused by high-criticality tasks are permitted, but not vice-versa.
This can be realised as a system mode-switch or form of graceful degredation.

There are many varied definitions of mixed criticality in the literature.
Some consider merely the combination of \gls{HRT}, \gls{SRT} and \gls{NRT} tasks, with criticality observed in that order.
Others allow for \gls{QoS} specifications, which can reflect criticality.
Systems where criticality can be specified explicitly (regardless of SRT/HRT specification) also exist.

A key observation about mixed-criticality systems is neither the strictness of the real-time model, nor rate-monotonic priorities have any direct correlation with the criticality of a task.
While in general critical tasks are \gls{HRT}, it is possible to have critical tasks that are \gls{SRT}, for instance, object tracking algorithms whose \gls{WCET} depends on factors external to the software system.

None of the scheduling algorithms so far directly support mixed-criticality systems.
\gls{RBED} is the closest, although it assumes a direct relationship between criticality and real-time model, with the assumption that \gls{HRT} tasks are more critical than \gls{SRT} tasks which are more critical than \gls{NRT} tasks.

Scheduling algorithms for mixed-criticality systems are a hot-topic in the real-time community.
In this section we briefly present a few such algorithms.


\subsection{Zero Slack Scheduling}

\Citet{deNiz_LR_2009} propose a scheduling approach that can handle multiple levels of criticality, called \gls{ZS} scheduling.

\gls{ZS} scheduling is based on the fact that tasks rarely use their \gls{WCET}.
This means that resource reservation techniques like \gls{CBS} without slack donation result in low effective utilisation.
ZS scheduling takes the reverse approach: high criticality tasks steal utilization from lower criticality tasks.
This involves calculating a \gls{ZS} instant - the last point at which a task can be scheduled without missing its deadline.
Under overload, the \gls{ZS} scheduler makes sure that high criticality tasks are scheduled by their \gls{ZS} instant, such that they cannot be preempted by lower criticality tasks.

Implementations of \gls{ZS} scheduling can be built using any priority-based scheduling technique, however in the initial work \gls{FP} with \gls{RM} priority assignment is used.
The \gls{ZS}\gls{RM} scheduler is proven to be able to schedule anything that standard \gls{RM} scheduling can, whilst maintaining the asymmetric protection property.
\gls{ZS} scheduling can be combined with temporal isolation via bandwidth servers.

% TODO possible rewrite
\gls{ZS} scheduling has been adapted to use a \gls{QoS} based resource allocation model~\citep{deNiz_WSRR_2012}, in the context of \glspl{UAV}.
Many models of real-time systems assume that \glspl{WCET} for real-time tasks are stable and can be calculated.
However, \glspl{UAV} have complicated visual object tracking algorithms where \gls{WCET} is difficult to calculate, and execution time varies with the number of objects to track.
In practice, \Citet{deNiz_WSRR_2012} found that \gls{ZS}\gls{RM} scheduling resulted in \emph{utility inversion} --- where lower utility tasks prevent the execution of higher utility tasks.
Although assuring no criticality inversion occurred with a criticality based approach, under overload, some tasks offer more utility than others with increased execution time.
As a result, the authors replace criticality in the algorithm with a utility function.
Two execution time estimates are used for real-time tasks --- \gls{NCET} and \gls{OCET}, each having their own utility.
The goal of the scheduler is to maximise utility, under normal operation and overload.

% TODO vestal
% TODO quest

\subsection{Mixed Criticality and Certification}
\label{sec:multiple-criticality}

An approach to mixed-criticality scheduling that involves two different WCET estimates arises due to the pessimism of \glspl{CA}.
High criticality tasks in safety-critical systems require certification, conducted by a \gls{CA}.
Note that tasks of lower criticality may not require certification.

\Glspl{CA} provide {\gls{WCET}} estimates that must be schedulable, however they are often very pessimistic.
This results in a tasks with two {\gls{WCET}} estimates, one very pessimistic one from the \gls{CA} and a less pessimistic one from the system designers or automated tools.
As a result of this, a family of mixed-criticality schedulers exists that handle high criticality tasks with two {\gls{WCET}} estimates, and low-criticality tasks.
The scheduling algorithm will always schedule high-criticality tasks.
If high-criticality tasks finish before the lower \gls{WCET} estimate, lower criticality tasks are also scheduled.
Otherwise, tasks of lower criticality may not be scheduled at all.
An \gls{EDF} based algorithm is presented in \citet{Baruah_BDMVS_2011}, which is generalised to an unlimited amount of criticality levels.
An \gls{FP} based approach is implemented in \citet{Pathan:phd}, where run-time monitoring is used to switch between criticalities.
Some tasks may be dropped in order to better utilise processors without violating certification requirements.

%TODO{more mixed-criticality scheduling algorithms}
%TODO{mixed-criticality resource sharing algorithms}
% TODO mixed criticality resource sharing protocols

\section{Summary}

%TODO{rewrite to include whole chapter}

Traditional scheduling algorithms, like \gls{EDF} and \gls{FP}-\gls{RM} schedule processor time but do not consider criticality differences between tasks, and also trust all tasks to stay within their \gls{WCET}.
Due to pessimism in \gls{WCET} estimates, this results in low utilisation in such systems and also prevents systems of mixed-criticality being constructed in a safe way.

Mixed-criticality systems require at minimum temporal isolation, however the asymmetric protection property allows for higher utilisation in systems.
\gls{EDF} and \gls{FP} scheduling can be adapted to have temporal isolation, or another approach, like PFair scheduling can be used to provide temporal isolation.
Much research has been done into scheduling algorithms that provide asymmetric protection, but the consequences of practical implementations in \glspl{OS} have yet to be explored.

In the next chapter, we survey existing operating systems and systems techniques with respect to temporal isolation capability, resource sharing, and asymmetric protection.

