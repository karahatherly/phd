\chapter{Introduction}

Criticality of a software system refers to the severity of the impact of a failure.
In a high-criticality system, failure risks significant loss of life or damage to the environment.
In a low-criticality system, failure may risk a downgrade in user-experience.
As criticality of a software system increases, so too does the cost and time to develop that
software: raising the criticality also raises the assurance level, with the highest levels requiring
extensive, expensive, independent certification.

For modern cyber-physical systems, including autonomous aircraft and other vehicles, the traditional
approach of isolating systems of different criticality by using completely separate physical
hardware is no
longer practical, being both restrictive and inefficient: restrictive in that physical isolation
prevents the construction of modern cyber-physical systems; inefficient in terms of
under-utilised hardware resources.
The result is \emph{mixed-criticality} systems, where software applications with different criticalities
execute on the same hardware. Sufficient mechanisms are required to ascertain that software in
mixed-criticality systems is isolated. Otherwise, all software on shared hardware is
promoted
to the highest criticality level, driving up costs to impractical levels. For mixed-criticality
systems to be
viable, both spatial and temporal isolation are required.

% introduce challenges, example
However, mixed-criticality systems have conflicting requirements that challenge \glspl{OS} design:
they require distrusting components of different criticalities to share resources and must
degrade gracefully in the face of failure.  For example, an \gls{AAV} has multiple inputs to its
flight-control algorithm: object detection, to avoid flying into obstacles, and navigation, to get
to the desired destination.  Clearly the object detection is more critical than navigation, as
failure of the former can be catastrophic, while the latter would only result in a non-ideal route.
Yet the two subsystems must cooperate; accessing and modifying shared data thus cannot be fully
isolated.

The \gls{AAV} is an example of a mixed-criticality system, a notion that originates in avionics and its
need to reduce \gls{SWaP} by consolidating growing functionality onto a smaller
number of physical processors. More recently the
\gls{MCAR}~\citep{Barhorst_BBHPSSSSU_09} program was launched, which recognises that in order to
construct fully autonomous systems, critical and less critical systems must be able to share
resources. However, resource sharing between components of mixed criticality is heavily restricted by current
standards.

% what's wrong with static partitioning
While mixed-criticality systems are becoming the norm in avionics, this is presently in a very restricted form: in the
ARINC 632 standard~\citep{ARINC653}, the system
is orthogonally partitioned spatially and temporally, and partitions are scheduled with fixed time
slices. Shared resources are permitted but can only be accessed through fixed-time
partitions; in other words, a critical component must not
trust a lower criticality one to behave correctly. This limits integration and cross-partition
communication, and implies long interrupt latencies and poor resource utilisation. 
% not just planes
These challenges are not unique to avionics: top-end cars exceeded 70 processors ten years
ago~\citep{Broy_KPS_07}; with the robust packaging and wiring required for vehicle electronics, the
SWaP problem is obvious, and will be magnified by the move to more autonomous operation. Other
classes of cyber-physical systems, such as smart factories, will experience similar challenges.

% let's use the WCET
% finally, overcommitting
One could reduce the number of separate processors without mixing criticalities by simply consolidating 
systems of the same criticality level, however, this is does not lead to efficient use of resources. 
High-criticality systems that are subject to high levels of assurance frequently have very
pessimistic \gls{WCET} estimates,
which are often orders of magnitude beyond the average execution time due to the limitations in analysis,
and the complexity of modern hardware~\citep{Wilhelm_EEHTWBFHMMPPSS_08}. However, in current systems the full \gls{WCET} must be
statically reserved for the high criticality tasks. By building mixed-criticality systems, where
low-criticality tasks---for which temporal interference can lead only to degradation in service---we can
leverage the unused capacity from high-criticality tasks. 

Fundamental to building mixed-criticality systems is the concept of \emph{asymmetric protection},
which differs from strict temporal isolation in that only the highest criticality systems are
guaranteed top levels of service. Less-critical software is not completely isolated, and can be
affected by high-criticality software, but not vice versa. 

% more than consolidation
Finally, mixed-criticality systems are about more than basic consolidation and leveraging excess
resources; they can achieve more
than traditional physically isolated systems by allowing actual resource sharing. 
Consider the driving software of a self-driving car: it may take inputs from various sensors
which detect objects, and also input from a \gls{GPS} navigation unit, and traffic data from an
internet-connected
service providing alternate route information. All of these systems \emph{must} provide input to the
shared driving software, which actually makes decisions about what commands to issue to the car.
Clearly, the object detection is more critical than the \gls{GPS}, which in turn is more critical than the
route information service. In fact, the route information service---being connected to the
internet---is not even a trusted service: it is subject to attacks, such as denial-of-service. 

Allowing untrusted, less critical components to
share hardware and communicate with more critical components, far more sophisticated software can be
introduced to the system. Examples include heuristics that are common in artificial
intelligence algorithms, or internet-connected software which by its nature cannot be completely
trusted. Both of these use-cases are far too complex to certify to the highest criticality standard,
but are essential for emerging cyber-physical systems like self-driving cars. The solution is to
co-locate these services, and provide strong isolation and safety guarantees to assure
correctness.

Our goal is to develop trustworthy, high-assurance \gls{OS} mechanisms that provide for the unique
requirements of mixed-criticality systems, without requiring all systems to be promoted to the highest
criticality in the system. 
The implementation platform will be the \selfour~\citep{Klein_EHACDEEKNSTW_09}
microkernel, which is has been designed for the high-assurance, safety-critical domain.

Concisely, the goals of this research are to provide:
\begin{enumerate}[label=\textbf{G\arabic*}] 
    \item\label{G1} A principled approach to
    processor management, treating time as a fundamental kernel resource, while
    providing mechanisms for asymmetric protection, a key requirement of mixed-criticality systems;
\item\label{G2} Safe resource sharing between applications of different criticalities, assurance levels and
    temporal requirements.  
\end{enumerate}

\section{Motivation}
\label{sec:motivation}

% expand on notion of criticality with more detail and examples. Give enough background to justify contributions.
As noted in the introduction, the \emph{criticality} of a system reflects the
severity of failure, where higher criticality implies higher severity.  Table
\ref{tab:criticality_table} shows criticality levels considered when designing
software for commercial aircraft in the United States.

\begin{table}
     \centering
     \rowcolors{2}{gray!25}{}
     \begin{tabular}{ l p{10cm}} \toprule
         \emph{Level}   & \emph{Impact} \\ \midrule
         Catastrophic   & Failure may cause multiple fatalities, usually with loss of the airplane. \\
         Hazardous      & Failure has a large negative impact on safety or performance, or reduces the
                          ability of the crew to operate the aircraft due to physical distress or 
                          a higher workload, or causes serious or fatal injuries among the passengers.\\
         Major          & Failure significantly reduces the safety margin or significantly increases
                          crew workload. May result in passenger discomfort (or even minor
                          injuries).\\
         Minor          & Failure slightly reduces the safety margin or slightly increases crew
                          workload. Examples might include causing passenger inconvenience or a
                          routine flight plan change. \\
         No Effect      & Failure has no impact on safety, aircraft operation or crew workload. \\
         \bottomrule
     \end{tabular}
     \caption[Criticality levels from DO-178C]{Criticality levels from DO-178C, a safety standard for commercial aircraft.}
     \label{tab:criticality_table}
 \end{table}

As the criticality level rises, so do the assurance levels: higher engineering and safety standards are required for higher criticality levels, up to
certification by independent \glspl{CA} at the highest level, which is a time-consuming,
expensive and restrictive process. Additionally, requirements specified by \glspl{CA} are highly
cautious and pessimistic, which, when combined with safety strategies such as redundant resources,
leads to large amounts of excess capacity in processing power. 

Consequently, highly
critical software is expensive to develop and tends to have low complexity in order to
minimise costs. Any software that is not fully isolated from a critical component is promoted to
that level of criticality, increasing the production cost, and imposing strict requirements.

Traditionally, systems of different criticality levels were fully isolated with
air gaps between physical components. However, given the increased amount of
computing in every part of our daily lives, the practice of physical isolation
has resulted in unscalable growth in the amount of computing hardware in
embedded systems, with some modern cars containing over 100
processors~\citep{Hergenhan_Heiser_08}. The practice of physical separation is no 
longer viable for three reasons: \gls{SWaP}, efficiency, and resource sharing.

\subsection{SWaP}

First, systems with air-gaps require increased physical
resources as each extra processor comes with extra cabling and power requirements,
increasing production costs and environmental impact.
For vehicles, especially aircraft, this goes further to reduce their function; the
heavier the system, the more fuel it requires, especially when considering 
the redundancy built into these systems for safety purposes: often each component is double- or
triple-redundant. 

\subsection{Efficiency} 

However, \gls{SWaP} alone could be reduced by consolidating systems of the same
criticality. Ignoring the fact that this also consolidates points of failure (redundant systems by
definition, cannot be consolidated), this alone is insufficient to completely address \gls{SWaP}
challenges. The higher the assurance required of a system, the more over-provisioned the hardware is: not only in
redundancy but in excess capacity. As mentioned previously, \gls{WCET}
estimates may be orders of magnitude larger than the typical execution time, and
computation of safe \gls{WCET} bounds for non-trivial software tends to be highly pessimistic
\citep{Wilhelm_EEHTWBFHMMPPSS_08}. At the same time, the core \emph{integrity property} of a
high-criticality, real-time system is that deadlines must always be
met, meaning that there must always be time to let such activities execute their \emph{full \gls{WCET}}.
Consequently, consolidating high-criticality
systems only ameliorates the problem slightly: the pessimism inherent in high-assurance systems is
also consolidated, leaving unused, excess hardware resources.

High-utilisation of hardware to address SWaP challenges is therefore only possible with the advent
of mixed-criticality systems, which can leverage the excess capacity for less critical, less time-sensitive
software.

\subsection{Resource Sharing}

Mixed-criticality systems also bring opportunities for new types of
systems, and are indeed required for emerging cyber-physical systems like
advanced driver assistance systems, autonomous vehicles and aircraft.

\begin{table} 
\rowcolors{2}{gray!25}{}
\centering
\begin{tabularx}{\textwidth}{lXl}\toprule
    \emph{System}            & \emph{Purpose}                                                         & \emph{Criticality} \\\midrule
     Obstacle detection      & Safety: failure can lead to collision, which could lead to significant
    damage and loss of life. & Catastrophic    \\
    \gls{GPS} Navigation     & Route planning:  failure can lead to an incorrect turn and further
    time travelling.         & Minor \\
     Traffic service         & Route planning: failure can lead to a slower trip, by failing to
    avoid congested paths.
    & Minor \\
    \bottomrule
\end{tabularx}
\caption{Fictional example systems in a self-driving car.}
\label{tab:self-driving-car}
\end{table}

Consider the systems required for a self-driving car to determine which commands to issue the vehicle,
as outlined in \Cref{tab:self-driving-car}. The object-detection is the most critical, and is
generally comprised of a host of sensors: infra-red, LIDAR, cameras, and radar, which themselves
are subject to different criticality levels. Object-detection,
especially from image data, is a function of the amount and complexity of data available: when
driving in desert, compared to driving in a city, far less input is available. It is also the
most critical system in our example, with failure leading to potentially disastrous collisions.

However, a GPS navigation service is also required to determine the route to take, and finally a
traffic service which allows cars to avoid congestion. Although the same criticality, the GPS
service is likely more highly-assured than the traffic service: the traffic service is connected to
the internet, requiring complex network drivers, and subject to attacks from remote attackers. 
In fact, the fastest way to integrate a traffic service is to run a large, open source code base
with existing network drivers like Linux, which has no assurance level. 

All three systems are important to the car manufacturer: a bad review due to poor navigation, or not
avoiding a traffic jam, can have a marked impact on sales. The three systems must access the same
shared resource (the driving logic), which requires the system to be mixed-criticality: the traffic
service, and to a lesser extent the GPS, are not practical to develop at high assurance levels. 
In order to gain high utilisation, the resources must be overbooked: the traffic service may have a
low-level guarantee to some hardware resources, but the object-detection service may infringe
on that resource occasionally. If the traffic service is statically assigned its resource
allocation, its utility may decrease, as it can run more frequently when the object-detection does not
require that time. Similarly, when stuck in traffic, the GPS service isn't much use: the traffic
service is of far more utility to find alternate routes. Conversely, when on a highway at high speed, the GPS
service requires more processing time, and the traffic service can run less frequently. 

Consequently, mixed-criticality shared resources are integral to future cyber-physical
systems, something that is not possible with traditional separation
of physical hardware. At the same time, for high system utilisation, 
asymmetric protection, and over-booking are required to address SWaP challenges. Finally, without
sufficient mechanisms, none of this system is possible, as developing such a system to high
assurance levels is not practical.

\section{Definitions}

\begin{description}
    \item[Mixed-criticality] In the real-time community, much work has been
conducted around a theoretical model introduced by \citet{Vestal_07} which we discuss in
\cref{sched:mixed-criticality-schedulers}.
The focus on this thesis is for the broader definition of mixed-criticality, such that software of
different levels of criticality can safely share hardware, and not specifically the model
presented by \citet{Vestal_07} and beyond~\citep{Burns_Davis_17}, although it is discussed in
\cref{chap:scheduling}.
\item[Temporal isolation] For a system $A$ to be temporally isolated from system $B$, $B$ cannot
        cause temporal failures in $A$. This does not necessarily mean that $B$ cannot affect $A$,
        but that any temporal effect $B$ can have on $A$ is deterministic and bounded, such that $A$
        is correct regardless of $B$. 
\item[Asymmetric Protection] In order to leverage an overbooked system, high-criticality tasks
        must be able to cause failures in low-criticality tasks but not vice-versa. Another way to
        state this is that \emph{criticality inversion} must be bounded, where a low-criticality
        task must not cause failures in a high-criticality task.
\end{description}


\section{Objectives}

Given their improvements to \gls{SWaP}, function and efficiency, mixed-criticality systems offer
great advantages over the traditional physical isolation approach. 
\citet{Ernst_DiNatale_16} identify two sets of mechanisms that need to be provided in order to
support true mixed-criticality systems:

\begin{enumerate}
    \item operating system kernels and schedulers that guarantee resource
        management to provide independence in the
        functional and time domain; separation kernels
        are the most notable example;
    \item mechanisms to detect timing faults and control
        them, including monitors, and the scheduling
        provisions for guaranteeing controllability in the
        presence of faults.
\end{enumerate}


\section{Approach}

In this thesis we look to systems and real-time theory related to scheduling, resource allocation
and sharing, criticality and trust to develop a set of mechanisms required in an \gls{OS} to 
support mixed criticality systems. We implement those mechanisms in \selfour and develop a set of
microbenchmarks and case studies to evaluate the implementation. 

\Cref{chap:background} establishes the basic terminology required to present
the remaining ideas, including an introduction to real-time scheduling and resource-sharing theory.
We also introduce the concept of a resource kernel, an existing approach to providing principled
access to time as a first class resource.

In \Cref{chap:scheduling} we examine in detail the theoretical models and methods for achieving temporal
isolation and safe resource sharing in traditional, real-time systems and show that sufficient
theory exists for resource-overbooking and asymmetric protection.

\Cref{chap:operating-systems}
investigates systems support for the same concepts; by surveying existing commercial, open-source
and research operating systems we show that in the current state of the art, support for resource
overbooking and asymmetric protection is insufficient for modern, cyber-physical systems

\Cref{chap:sel4} presents the final piece of background, presenting the existing concepts which make
our implementation platform, \selfour, an excellent target for high-assurance systems with its
existing spatial-resource isolation mechanisms. However, we also show that, like the other operating
systems considered in the chapter before it, current mechanisms are insufficient for temporal
isolation, asymmetric protection, and resource overbooking. 

We then present in \cref{chap:model} a model for mechanisms required to build mixed-criticality operating systems,
including capability-based access control to processing time which allows for overbooking and does
not limit user-level policy. Additionally, we provide new mechanisms for resources that can be
shared safely between systems of different criticalities. Our model is designed to integrate with
\selfour, however has wider applications to \gls{OS} design for mixed-criticality systems.

\cref{chap:implementation} delves deeply into the implementation details, presenting a full, mature
implementation of our model along with discussions of design trade-offs and limitations. 

Finally, \cref{chap:evaluation} presents a detailed set of benchmarks and case studies on a variety of x86
and ARM platforms, showing the overheads
of our implementation, demonstrating temporal isolation in systems with and without shared
resources, and showing how resource overbooking and asymmetric protection can be achieved.

\section{Contributions}

We make the following specific contributions:

\begin{itemize}
    \item a design and model for fine-grained access control to processing time, without
        imposing strict limitations on system policy or introducing performance overheads, and
        without requiring sacrifices to integrity or confidentiality;
    \item an implementation of the model in the high-assurance, non-preemptible \selfour microkernel,
        and an exploration of the simplicity of the model and its integration with the existing
        model, which provides strong isolation properties;
    \item an evaluation of the implementation, demonstrating low overheads and temporal isolation
        between systems sharing a processor and other resources;
    \item user-level implementations of dynamic schedulers and resource sharing servers which
        demonstrate that a variety of policies are not only possible to implement, but low overhead.
\end{itemize}

\section{Scope}

We focus on uniprocessor and \gls{SMP} systems with \glspl{MMU} for ARM and x86, where our focus is
on safety, through integrity and availability. We leave security concerns such as covert channels to
future work. Additionally, we assume a constant processor speed, and leave variable-speed processors
and energy-saving mechanisms to future work.
