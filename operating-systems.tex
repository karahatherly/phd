

\chapter{Operating Systems}
\label{chap:operating-systems}

In this chapter we provide a survey of existing operating systems and mechanisms for building
mixed-criticality systems. We evaluate
the scheduling and resource sharing policies and mechanisms available, with a focus on temporal isolation,
asymmetric protection, policy freedom, and resource sharing.  

First, we look at the \emph{\gls{POSIX}} standard which underlies many commercial and open source operating
systems. Then we examine what is available in Linux other open source operating systems, before
examining commercial offerings. Finally, we survey existing relevant operating systems
from systems research, deeply examining techniques that can be leveraged to build mixed-criticality
systems, including isolation and resource sharing techniques.

\section{POSIX}

The \gls{POSIX} standard specifies \gls{RTOS} interfaces~\citep{Harbour_93} for scheduling and
resource sharing, which
influence much \gls{OS} design.  Scheduling policies specified by \gls{POSIX} are shown in
\Cref{tab:posix-sched}. 

\begin{table}
\centering
\rowcolors{2}{gray!25}{white}
\begin{tabular}{lp{.7\textwidth}}\toprule
    \emph{Policy}  & \emph{Description} \\\midrule
    \schedfifo     & Real-time tasks can run at a minimum of 32 fixed-priorities until they are preempted or yield. \\
    \schedrr       & As per \schedfifo but with an added timeslice. If the timeslice for a thread expires, it is added to the tail of the scheduling queue for its priority.\\
    \schedsporadic & Specifies sporadic servers as described in \Cref{p:sporadic} and can be used
    for temporal isolation. For practical requirements, the POSIX specification of \schedsporadic
    specifies a maximum number of replenishments which is implementation defined. \\\bottomrule
\end{tabular}
\caption{\gls{POSIX} real-time scheduling policies}
\label{tab:posix-sched}
\end{table}

\citet{Faggioli_08} provides an implementation of \schedsporadic, which \citet{Stanovic_BWH_10}
used to show that the POSIX definition of the sporadic server is incorrect and can allow tasks to
exceed their utilisation bound.  The authors provide a modified algorithm for merging and abandoning
replenishments which fixes these problems, of which corrections to the pseudo code were published by
\citet{Danish_LW_11}.  In further work \citet{Stanovic_BW_11} show that while sporadic servers
provide better response times than polling servers under average load, under high load the overhead
of preemptions due to fine-grained replenishments causes worse response times when compared to
polling servers.  Consequently, they evaluate an approach where servers alternate between sporadic
and polling servers depending on load, where the transition involves reducing the maximum number of
replenishments to one and merging available refills.

Resource sharing in the \gls{POSIX} \gls{OS} interface is permitted through mutexes, which can be
used to build higher synchronisation protocols.  \Cref{tab:posix-mutex} shows the specified
protocols. 

\begin{table}
\centering
\rowcolors{2}{gray!25}{white}
\begin{tabular}{lp{.7\textwidth}}\toprule
\emph{Policy} & \emph{Description} \\\midrule
\noprioinherit & Standard mutexes that do not protect against priority inversion. \\
\prioinherit  & Mutexes with \gls{PIP} to prevent priority inversion, recall \Cref{sec:pip}. \\
\prioprotect & Mutexes with \gls{HLP} to prevent priority inversion, recall \Cref{sec:hlp}. \\
\bottomrule
\end{tabular}
\caption{\gls{POSIX} real-time mutex policies for resource sharing.}
\label{tab:posix-mutex}
\end{table}

Although \gls{POSIX} provides \schedsporadic which can be used for temporal isolation (however
flawed), the intention of the policy is to contain aperiodic tasks. 
However, temporal isolation of shared resources is not possible with \gls{POSIX}.
This is because \schedsporadic allows threads to run at a lower priority if 
they have exhausted their sporadic allocation, meaning those threads can still access resources
even when running at lower priorities. In fact, running at lower priorities ensures that threads
contained by sporadic servers can unlock locked resources: however, it also does not bound
locking, or provide ways to pre-empt locked resources.
As a result, \gls{POSIX} is insufficient for
mixed-criticality systems where tasks of different criticalities share resources.  Few \glspl{OS}
implement the full \gls{POSIX} standard, however many incorporate features of it, including Linux.

\section{Existing operating systems}

There is a significant gap between real-time theory, as surveyed in the last chapter, and real-time
practice. Here we provide a survey of existing open source and commercial operating systems with
real-time mechanisms to demonstrate the status quo.

\subsection{Open source}

\subsubsection{Linux}

While Linux cannot be considered a real-time operating system for high criticality applications, it
is frequently used for lower criticality applications with \gls{SRT} demands.  Additionally, Linux
is often used as a platform for conducting real-time systems research. 
% TODO cite completely fair scheduler
Linux has fixed-priority preemptive scheduler which is split into scheduling classes.  Real-time
threads can be scheduled with \gls{POSIX} \schedfifo and \schedsporadic. Best-effort threads are
scheduled with \gls{CFS}, and real-time threads are scheduled either \gls{FIFO} or round-robin, and
are prioritised over the best-effort tasks.  Fixed priority threads in Linux are completely trusted:
apart from a bound on total execution time for real-time threads which guarantees that best-effort
threads are scheduled (referred to as real-time throttling~\citep{Corbet_08}), individual temporal
isolation is not possible.

Linux version 3.14 saw the introduction of an \gls{EDF} scheduling class~\citep{Corbet_09},
which is between the fair and the fixed priority scheduling classes.  The \gls{EDF} implementation
allows threads to be temporally isolated using \gls{CBS}.

Scheduling in Linux promotes the false correlation we see in many systems: real-time tasks are
automatically trusted (unless scheduled with \gls{EDF}) and assumed to be more important, or more
critical, than best-effort tasks.  In reality, criticality and real-time strictness are orthogonal.
Linux does not provide any mechanisms for asymmetric protection beyond priority.

On the resource sharing side Linux provides real-time locking via the \gls{POSIX} API as per
\Cref{tab:posix-mutex}, which is unsuitable for mixed-criticality shared resources.

Numerous projects attempt to retrofit more extensive real-time features onto
Linux.  We briefly summarise major and relevant works here. 

One of the original
works~\citep{Yodaiken_Barabanov_97} runs Linux as a fully-preemptable task via virtualisation and
kernel modifications, and runs real-time threads in privileged mode. Interrupts are virtualised and
sent to real-time threads, only directed to
Linux if required. Consequently, real-time tasks do not have to suffer from long interrupt
latencies, however it also means that devices drivers need to be rewritten from scratch for
real-time. This approach is clearly untenable in a mixed-criticality system, given all real-time
threads are trusted. 

\litmus~\citep{Calandrino_LBDA_07} is an extension of Linux that allows for pluggable real-time
schedulers to be easily developed for testing multiprocessor schedulers which schedule kernel
threads. Real-time schedulers run at a higher priority than best-effort threads, and schedulers can
be dynamically switched at run time. \litmus is not intended for
practical use, but for developing and benchmarking scheduling and resource sharing algorithms.
Implementations of global- and partitioned-, EDF and FP schedulers exist for LITMUS, in addition to
\emph{PFair} schedulers. A \gls{SS} implementation exists, as well as various multicore,
real-time locking protocols.

\linuxrk~\citep{Oikawa_Rajkumar_98} is a resource kernel implementation of Linux with scheduling,
admission control, and enforcement in the kernel. Every resource, memory, CPU time and devices was
time-multiplexed using a recurrence period, processing time and deadline. Reservations in \linuxrk
could be hard, firm of soft, which altered resource scheduling after a resource was exhausted. Hard
reservations were not scheduled again until replenishment, firm would only be scheduled if no other
undepleted reserve or unreserved resource use was scheduled, while soft allowed resource usage to be
scheduled at a background priority. \linuxrk is additionally often used to implement and test other
schedulers, such as \Gls{ZS} scheduling~\citep{deNiz_LR_09}, which was presented in
\cref{s:zero-slack-scheduling}.
 
Whilst Linux implementations are suitable for implementing algorithms, being used as test-beds and
even being deployed for non-critical \gls{SRT} applications, ultimately Linux is not a suitable
\gls{RTOS} for running safety-critical \gls{HRT} applications. The large amount of source code
results in a colossal trusted computing base, where it is impossible to guarantee correctness through
formal verification or timeliness through {\gls{WCET}} analysis.  Major reasons for adapting Linux
to real-time are the existing applications and wide array of device and platform support. For
mixed-criticality systems these advantages can by running Linux as a virtualised, guest \gls{OS} to run \gls{SRT}
and best-effort applications.

\subsubsection{RTEMS}

\citet{RTEMS:URL} is an open-source \gls{RTOS} that operates with or without
memory protection, although in either case it is statically configured.  Although it is an open
source project, RTEMS is used widely in industry and research.  The main scheduling policy is
\gls{FPRM}, however \gls{EDF} is also available with temporal isolation an option using \gls{CBS}.
No temporal isolation mechanisms are present for fixed-priority scheduling.  RTEMS provides
semaphores with \gls{PIP} or \gls{HLP} for resource sharing, as well as
higher level primitives for these. RTEMS does not provide mechanisms for shared resources, as target 
threads are trusted to complete critical sections within a determined \gls{WCET} provides no mechanism for isolation through shared resources.

\subsubsection{FreeRTOS}

\citet{FreeRTOS:URL} is another open-source \gls{RTOS}, however it only supports systems with \glspl{MPU}, not
\glspl{MMU}. The scheduler is preemptive \gls{FP} and \gls{PIP} is provided to avoid priority inversion.
%FreeRTOS can be configured to be tickless or not.


\subsection{Commercial RTOSes}
%TODO add details on resource sharing to this section
Several widely deployed \glspl{RTOS} are used commercially, the majority providing support for part or
all of \gls{POSIX}.  

\subsubsection{QNX Neutrino}

\citet{QNX_10} was one of the first commercial microkernels, widely used in the transport industry.
QNX is a separation based, first-generation microkernel that provides
\gls{FP} scheduling and resource sharing with POSIX semantics.  QNX satisfies many industry
certification standards, although these in practice do not require {\gls{WCET}} analysis or formal
verification of correctness. 

\subsubsection{VxWorks}

VxWorks~\citep{VxWorks_08} is a monolithic \gls{RTOS} deployed most notably in aircraft
and spacecraft.  It supports \gls{FP} scheduling with a native POSIX-compliant scheduler.  VxWorks
also has a pluggable scheduler framework, allowing developers to implement their own, in-kernel
scheduler.

\subsubsection{PikeOS}

PikeOS~\citep{PikeOS:URL} is a second-generation microkernel which implements ARINC 653~\citep{ARINC653} 
and runs RTOSes as paravirtualised guests in different partitions. Partitions are scheduled
statically in a cyclic fashion, and each partition has its own scheduling structure supporting 256
priorities.
An alternative design has been implemented for PikeOS~\citep{Vanga_BTB_17}, where reservations are
used to schedule low-latency, low-criticality tasks.
This is achieved by using ``\gls{EDF} within fixed priorities''~\citep{Harbour_Palencia_03}, which
schedules using EDF at specific priority bands, with combined with a pluggable interface for using a
reservation algorithm (\eg \gls{CBS}, \gls{SS}, \gls{DS}) to temporally contain threads. In order to achieve low-latency, these tasks are run
in the special partition of PikeOS, known as the system partition, which is scheduled at the same
time as the currently active partition and provides essential system services. However, these tasks
are intended to run without sharing resources or interfering with high-criticality tasks, which run
in their own partitions.

\subsubsection{Deos}

\citet{Deos:URL} is another RTOS which provides fixed-priority scheduling, with the addition of slack
scheduling, where threads can register to receive slack and are scheduled according to their
priority when there is slack in the system. Like PikeOS, Deos also implements ARINC 653 and a
defined subset of POSIX.

\subsection{Summary}

There are many other \gls{RTOS}es used commercially, but the general pattern is POSIX-compliant, 
\gls{FP} scheduling and resource sharing.
This brief survey shows that \gls{FP} scheduling is dominant in industry due to its predictable
behaviour on overload, specification in the
POSIX standard, and compatibility with existing, priority-based, best-effort systems.

Although temporal isolation is sometimes provided with the possibility of bounded bandwidth via
\glspl{CBS}, asymmetric protection is not provided, and support for temporal isolation in 
shared resources is non-existent. In addition to scheduling, code-bases are
generally large and complex, and beyond the grasp of modern {\gls{WCET}} analysis.  Although all of
these \gls{RTOS}es are deployed in safety critical systems, their support for mixed-criticality
applications is limited to the ARINC653 approach discussed in \cref{p:arinc}. 

\begin{table}
\centering
\rowcolors{2}{}{gray!25}
\begin{tabular}{lll}\toprule
  \emph{OS} & \emph{Scheduler}  & \emph{Temporal Isolation} \\\midrule
Linux       & \gls{FP} + \gls{EDF} & \gls{CBS} \\
RTEMS       & \gls{FP} + \gls{EDF} & \gls{CBS} \\
FreeRTOS    & \gls{FP}             & \no       \\
QNX         & \gls{FP}             & ARINC 653, \gls{SS} \\ 
VxWorks     & \gls{FP}             & ARINC 653   \\
PikeOS      & \gls{FP}             & ARINC 653    \\
Deos    & \gls{FP}             & ARINC 653\\
\bottomrule
\end{tabular}
\label{t:os-summary}
\caption{Summary of scheduling and temporal isolation mechanisms in surveyed open source and
commercial \glspl{OS}.}
\end{table}

\section{Isolation mechanisms}

We now look to systems research and explore mechanisms for temporal isolation and resource sharing
in research operating systems, exploring their history and the state of the art. First we briefly introduce each operating system that is surveyed,
before exploring in detail specific mechanisms 
that can be used to support mixed-criticality systems. We investigate 
how different \glspl{OS} address resource kernel concepts required to treat time as a first class
resource; scheduling, accounting, enforcement, admission. Additionally, we look at how
prioritisation, charging and enforcement are achieved, if at all, to achieve temporal isolation
across shared resources.

The majority of kernels surveyed here are microkernels, as introduced in
\cref{sec:background-operating-systems} and are as follows: 

\begin{itemize}
    \item Real-time Mach~\citep{Mercer_RZ_94, Mercer_ST_93}, a first-generation microkernel.
    \item The \gls{DROPS}~\citep{Haertig_BBHHMRSW_98}, a second
        generation, L4 microkernel.
    \item EROS~\citep{Shapiro_SF_99}, the first third-generation microkernel.
    \item Fiasco~\citep{Hohmuth_02} is a second-generation L4 microkernel, with fixed-priority scheduling.
    \item \textsc{Minix 3}~\citep{Herder_BGHT_06} is a traditional microkernel with a focus on 
        reliability rather than performance. 
    \item Tiptoe~\citep{Craciunas_KPRS_09} is a now-defunct research microkernel that also aims at
temporal isolation between user-level processes and the operating system.
    \item NOVA~\citep{Steinberg_Kauer_10} a third-generation microkernel and hypervisor.
    \item \composite~\citep{Parmer:phd} is a component-based \gls{OS} with similar with goals to a microkernel,
however with a more dominant focus on support for fine-grained components, and massive scalability.
    \item \citet{FiascoOC:URL}, a third-generation iteration of Fiasco, both microkernel and
        hypervisor.
    \item Barrelfish~\citep{Peter_SBBIHR_10} is a capability-based multi-kernel \gls{OS}, where a separate kernel runs on each processing core and kernels themselves share no memory and are essentially \emph{\gls{CPU}-drivers}.
    \item Quest-V~\citep{Danish_LW_11} is a separation kernel / hypervisor.
    \item \selfour~\citep{Klein_AEMSKH_14}, a third-generation microkernel with
        hypervisor support and a proof of functional correctness. We present \selfour 
        and its mechanisms in more detail in \cref{chap:sel4}.
\end{itemize}


\subsection{Scheduling}

As in commercial and open source \glspl{OS}, fixed-priority scheduling dominates in research, with
only Tiptoe and Barrelfish providing \gls{EDF} schedulers, although \minix has been adapted for 
real-time~\citep{Mancina_LFHGT_09}, by allowing the kernel's best-effort scheduling to be
set to \gls{EDF} on a per-process basis.   

\composite stands out, as it does not provide a scheduler or blocking semantics in the kernel at all,
requiring user-level
components to make scheduling decisions. \hires~\citep{Parmer_West_11} is a hierarchical scheduling framework built on top
of \composite. 
 \hires delivers timer interrupts to a root, user-level scheduling component, which are then forwarded
through the hierarchy to child schedulers.  Consequently, scheduling overhead increases as the
hierarchy deepens.  Child schedulers with adequate permissions use a dedicated system call to tell
the kernel to switch threads.  The kernel itself does not provide blocking semantics, which are also
provided by user-level schedulers.  This design offers total scheduling policy freedom, as
user-level scheduling components can implement all the goals of a resource kernel according to
their own policy.


\subsection{Timeslices and meters}

KeyKOS ~\citep{Bomberger_FFHLS_92} introduced a concept called \emph{meters}, which represented a
defined length of processing time. Threads required meters to execute, and once a meter was depleted
a higher authority was required to replenish the meter. Meters treat time as fungible: the mechanism
only quantifies the amount of time to be consumed, not when it must be consumed by.

L4 kernels~\citep{Elphinstone_Heiser_13} extended this with time slices, although in different ways.
Kernels like \selfour provide a timeslice which like meters is consumed as threads execute, but no
authority is invoked to replenish the meter: the thread is simply preempted and placed at the end of
the \gls{FIFO} scheduling queue for the appropriate priority with a refilled timeslice. NOVA
extended the idea with variable time slices, which represented an amount of time that a thread could
execute at a priority before preemption.

\TODO{Rephrase - address peters comment Surely even if time is a first class resource, it can be
exchanged... A task can transfer some of its time to another task}
In a system where time is treated as a first-class resource, time cannot be treated as fungible and
as such the timeslice/meter is not an appropriate mechanism alone for building mixed-criticality
systems with temporal isolation guarantees.

\subsection{Reservations}
% TODO finish unifying
Mach and EROS used \gls{DS}, Tiptoe \gls{CBS} and Barrelfish \gls{RBED}. 
An implementation of RBED has also been completed on OKL4~\citep{Petters_LHE_09}.
\Glspl{SS} are provided by Quest-V~\citep{Li_WCM_14} and QNX, which address the back-to-back
problem of \gls{DS} however require a more complex implementation.

Starting with Real-time Mach reservations are an existing mechanism used for temporal isolation.
However, temporal isolation in the form of resource reservations is more common. Barrelfish provides
an \gls{RBED} implementation, and Tiptoe a modified, variable bandwidth version of \gls{CBS}, while \minix provides hooks into the kernel
scheduler such that CBS can be implemented at user-level. For the fixed-priority \glspl{OS}, two broad
types of reservation are available: either a timeslice, which when exhausted schedules the thread
round-robin (NOVA, \fiascooc), or a budget and period pair, representing a bandwidth (Real-time Mach). 

Real-time Mach followed this model, incorporating reservations into a two-level fixed-priority
scheduler, where threads with
reserves would execute first, then threads without reserves and with
depleted reserves would be scheduled using a second level time-sharing scheduler. EROS would then
use the same scheduling mechanisms as Real-time Mach. \gls{DROPS} allowed processes to reserve a 
higher priority for a certain amount of cycles, before returning to a lower priority.

Quest-V~\citep{Danish_LW_11} provides reservations through \gls{SS}, however \IO and normal processes
are distinguished statically: \IO processes use polling servers and normal processes use sporadic
servers. In Quest-V, separate partitions are assigned to
different priority levels, and communication via shared memory and inter-processor interrupts 
is permitted between partitions.

Regardless of the algorithm used to implement a reservation there are some common patterns.  None of
the systems require a reservation to execute, instead the reservation provides a guarantee to a
certain amount of time, while threads with depleted time may be scheduled by a best-effort layer
scheduler in any slack time. All the systems surveyed perform admission tests in the kernel: if a
reservation is not schedulable, it is not allowed to be created. 

\subsection{Timeslice donation}

Recall from \cref{s:background-ipc} that in a microkernel, \gls{OS} services are implemented at
user-level where clients use \gls{IPC} to communicate with servers, in an \gls{RPC}-like fashion, as
illustrated in \cref{f:os-ipc}.

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{ipc-port}
    \caption{Thread execution during IPC between client and server}
    \label{f:os-ipc}
\end{figure}

Early implementations of IPC had clients send messages directly to servers by referencing the
thread ID. Later IPC message \emph{ports} were introduced to provide isolation; clients send
messages and wait for replies on ports, and servers receive messages on ports and reply to the
clients message on that port, removing the need for threads to know details about each other. 
Servers effectively provide resources shared with multiple clients, via IPC through ports. 

The heavy optimisation of second- and third-generation microkernels resulted in \emph{timeslice
donation}, and optimisation which avoided the scheduler~\citep{Heiser_Elphinstone_16}. 
Timeslice donation works as follows: the client calls the server, if the server is higher or equal
priority it is switched to directly without invoking the scheduler at all, effectively a yield.
The intuition is that in
a fast IPC system, the request should be finished before the timeslice expires. In reality, longer
requests do occur, so while the clients timeslice is used for the start of the request, the servers
timeslice is used beyond that. This results in no
proper accounting of the server's execution, and no temporal isolation.

Other kernels, like Barrelfish, allowed the sender to set a flag on a message specifying if
timeslice donation should occur.

\subsubsection{Scheduling contexts}
\label{s:sc-intro}

Thread structures in the majority of kernels contain the execution context (registers) and scheduling
information, such as priority and accounting information, in a single structure known as a \gls{TCB}.
Other kernels, including real-time Mach and NOVA, divide the TCB into an execution context and
\emph{scheduling context} in order to allow the scheduling context to
transfer between threads over \gls{IPC} for accounting and/or priority inheritance purposes.
\emph{Scheduling context donation} refers to a scheduling context transferring between threads over
\gls{IPC}. The contents of a scheduling context vary per implementation, which we now explore.

In the case of Real-time Mach, processor capacity reserves were the first form of scheduling context
split from execution context. Real-time Mach's scheduling contexts contained parameters for the deferrable
server, a more explicit form of
timeslice donation: when the scheduling context is passed between client and server, the scheduling
context of the client is billed for activity on the server's behalf. 
Message ports contained two flags indicating what policy should be applied to priority on \gls{IPC}:
one would enable running the server at the client's priority, and the other implemented \gls{PIP},
where pending clients would boost the priority of the server should a lower priority client be
executing a request~\citep{Kitayama_NT_93}. 

In Real-time Mach, this process was
compulsory: scheduling contexts would always travel over \gls{IPC}.
If a server exhausted the
donated reservation, it would finish the operation using the time-sharing scheduler.  
The approach taken by real-time Mach offers little in policy freedom in terms of accounting: 
servers must account time executed to its clients, and the time-sharing scheduler must be used to
finish the operation.

NOVA~\citep{Steinberg_WH_05} also provided scheduling contexts with donation over \gls{IPC}, where
scheduling contexts consisted of a timeslice and a priority. Unlike Real-time Mach, a bandwidth
algorithm was not used, simply a timeslice without a period, meaning that the timeslice is
replenished immediately, however threads are scheduled round-robin within their priority level, so
when a thread executes again is a function of other threads in the system.  In another
differentiating factor from Real-time Mach, instead of delegating expired timeslices to a
second-level scheduler, NOVA implements \emph{helping}~\citep{Steinberg_BK_10}, which is a form of
bandwidth inheritance, where pending clients not only boost the priority of the server, but the
server can account the current clients request to the pending client in order to finish the initial request. 

\fiascooc introduced scheduling contexts in order to allow paravirtualised guests to switch between
scheduling context with different parameters in order to provide flattened hierarchical
scheduling~\citep{Lackorzynski_WVH_12}, which prevents scheduling integrity violations
when scheduling multiple real-time guests by exporting scheduling information to the hypervisor.
Scheduling contexts in \fiascooc contained a budget, a
replenishment rule, and a priority, and guests 
can change scheduling contexts on priority switches and interrupt service routines.

% TODO rephrase
All the scheduling context donation policies implement a form of bandwidth inheritance, which
forces the use of \gls{PIP}, which has high preemption overhead. This conflicts with the
policy-freedom goal of a microkernel; out claim is \gls{PIP} does not belong in the kernel. 
Designs differ whether
scheduling context donation is required or optional.  Some designs allow multiple execution contexts
to be attached to one scheduling context, such that the scheduling context forms a secondary run
queue.  In others, multiple scheduling contexts can be bound to one execution context, allowing the
execution context to execute on any scheduling context with available execution time. 


\subsection{Accounting}

\TODO{Rewrite, describe where time is accounted to: the client or server, and explain the
difference}.

\subsection{Capabilities to time}
\label{s:os-capabilities}

Recall from \cref{s:b-capabilities} that capabilities~\citep{Dennis_VanHorn_66} are an established mechanism for
fine-grained access control to system resources.
Third-generation microkernels use capabilities for principled access to system resources, including 
KeyKOS, EROS, \fiascooc, NOVA, \selfour, \composite and Barrelfish. 

% TODO integrate
EROS introduced the
idea of a single-use reply capability, termed a \emph{resume} capability, which when invoked would
be consumed and allows the receiver to reply to the sender.  EROS also used what is known as an
\emph{entry} capability, which allowed the holder to invoke the services provided by a program
within a particular process. 

Prior uses of capabilities for controlling time include
KeyKOS~\citep{Bomberger_FFHLS_92}, which had capabilities to \emph{meters}, which granted the holder
the right to execute for the unit of time held by the meter.
However, the KeyKOS model treats time as fungible, with no guarantee
of \emph{when} the time will be provided, which makes this approach
unsuitable for real-time use.

EROS~\citep{Shapiro_SF_99} combined processor capacity reserves with capabilities rather than the
meters of KeyKOS. However, these reserves were optional: a two level scheduler first
scheduled the reserves with available capacity, then threads without reserves,
or with exhausted reserves, were scheduled.
Like any hierarchical scheduling model, this enforces a policy that
reduces flexibility.

Furthermore, hierarchical delegation has the significant disadvantage
of algorithmic utilisation loss~\citep{Lackorzynski_WVH_12}; this is a
direct result of the unfungible nature of time. Consider real
estate: like time, it is (arbitrarily) divisible but not fungible: If
a block is too small to build a house, then having a second,
disconnected block of the same size is of no help (unlike spatial resources in a kernel, which can
be mapped side-by-side). The implication is
that capabilities for time have a different flavour from those for
spatial resources---they cannot support hierarchical delegation
without loss, and cannot be recursively virtualised. While delegation is an
attractive property of spatial capabilities,
this delegation is not their defining characteristic, which is actually
\emph{prima facie evidence of access}; in the case of time
capabilities, the access is to processor time.

\composite recently introduced temporal capabilities
(tCaps)~\citep{Gadepalli_GBKP_17} reminiscent of
the meters of KeyKOS in that they represent a scalar unit of time.
Unlike KeyKOS, tCaps integrate with user-level scheduling, decoupling access control
from scheduling. An initial capability \emph{Chronos} provides authority to all time, and this capability
can used to replenish tCaps by a top-level scheduler. The kernel up calls user-level schedulers 
which must then provide a tCap and a thread to execute. A tCap is always active in the system with
any time billed to it. The top-level scheduler delegates fixed amounts of time from the initial,
infinite tCap, which can then be further delegated and split according to the scheduling policy,
which could be simple fixed-priority or a more complex scheduling hierarchy, such as that presented
in \hires~\citep{Parmer_West_11}. If all time
in a tCap is depleted, other, non-depleted tCaps will be scheduled until eventually the top-level
tCap is scheduled. For efficiency, tCap delegation is limited to a constant of 16. 

\begin{table}
\centering
\rowcolors{2}{}{gray!25}
\begin{tabular}{lll}\toprule
  \emph{OS} & \emph{Scheduler}  & \emph{Temporal Isolation} \\\midrule
Real-Time Mach & \gls{FP}          & \gls{DS}    \\
EROS        & \gls{FP}             & \gls{DS}    \\
Tiptoe      & \gls{EDF}            & \gls{CBS} \\
Barrelfish  & \gls{EDF}            & \gls{RBED}  \\
DROPS       & \gls{FP}             & \no \\
NOVA        & \gls{FP}             & \no  \\
Quest-V     & \gls{FP}             & \gls{SS} \\
\selfour    & \gls{FP}             & \no                \\
\composite   & user level           & user level         \\
    \minix      & \gls{FP} \& \gls{EDF} & \gls{CBS} \\
\bottomrule
\end{tabular}
\label{t:os-summary}
\caption{Summary of scheduling and isolation mechanisms in surveyed \glspl{OS}.}
\end{table}



\section{Summary}
% TODO rewrite to reflect update
In this chapter we have reviewed existing real-time operating systems and techniques applicable to
treating time as a first class resource, as part of our goal to design microkernel mechanisms for 
the support of mixed-criticality workloads. 
As we have seen, many existing systems conflate criticality and time sensitivity 
in a single value: priority. A further assumption is that high criticality, time sensitive tasks are
always trusted, one the falls apart in the mixed criticality context.

% TODO factor in\subsection{Summary}

While real-time literature is divided between which real-time scheduling algorithm should be
deployed as the core of real-time systems (\gls{EDF} or \gls{FP}), no such divide exists in industry
where the vast majority of \glspl{OS} provide \gls{FP}.  \gls{FP} is far more dominant due to its
inclusion in \gls{POSIX} and  % TODO finish
Except in a pure research sense, kernels that provide
\gls{EDF} do so in addition to \gls{FP}.  Resource reservations and \gls{EDF} are more common in
research OSes, whilst commercial and open source products are heavily influenced by ARINC 653 and
provide static partitioning. 
 

The \emph{criticality} of a component reflects its importance to the
overall system mission.
Criticality may reflect the impact of failure~\citep{ARINC653} or the
utility of a function. An MCS should degrade gracefully, with
components of lower criticality (which we will for simplicity refer to
as \crit{low} components) suffering degradation before higher
criticality (\crit{high}) components.

\emph{Time sensitivity} refers to how important it is to a thread to
get access to the processor at a particular time. For best-effort activities, time is
fungible, in that only the amount of time allocated is of
relevance. In contrast, for a hard real-time component, time is
largely unfungible, in that the allocation has no value if it occurs after
the deadline; soft real-time components are in between.

Finally, \emph{trust} refers to the degree of reliance in the correct
behaviour of a component. Untrusted components may fail completely
without affecting the core system mission, while a component which
must be assumed to operate correctly for achieving the overall mission
is trusted. A component is \emph{trustworthy} if it has undergone a process
that establishes that it can be trusted, the degree of trustworthiness
being a reflection of the rigour of this process (testing,
certification, formal verification)~\citep{Verissimo_NC_03}.
\Cref{plot:ternary} illustrates these axes.

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{ternaryaxis}[
            xlabel=Criticality,
            ylabel=Trustworthiness,
            zlabel=Real-time sensitivity,
            label style=sloped,]
        \end{ternaryaxis}
    \end{tikzpicture}
    \caption{Commonly conflated attributes of systems software}
    \label{plot:ternary}
\end{figure}

In practice, criticality and trust are closely aligned, as the most
critical parts should be the most trustworthy.
However, criticality must be decoupled from time sensitivity in MCS.
Referring back to the
example in the introduction, interrupts from networks or buses have
high time sensitivity, but low criticality (i.e.\ deadline misses are
tolerable), while the opposite is true for the flight control component.
Similarly, threads (other than the most critical ones which should
have undergone extensive assurance) cannot be
trusted to honour their declared WCET.

Our claim is that how these attributes are conflated is
policy that is specific to a system.
We need a mechanism that allows  enforcing time limits, and thus
isolate the timeliness of critical threads from those of untrusted,
less critical ones.
Reservation-based kernels often allow for a form of over-committing where
best-effort threads are run in the slack-time left by unused reservations or unreserved CPU.
However, this also aligns criticality and time-sensitivity, and
enforces a two-level scheduling model.

If trustworthiness and real-time sensitivity are not conflated, many assumptions about real-time
scheduling fail.
Much real-time analysis rely on threads having a known \gls{WCET}, which implies that those threads
are predictable, which implies trust.
If a real-time thread is not expected to behave correctly, one cannot
assume it will surrender access to the processor voluntarily.
Consequently, the \gls{PIP}/\gls{BWI} based scheduling-context donation mechanisms seen in this chapter are
insufficient, forcing not only a protocol which causes extensive preemption overhead, but 
requiring shared servers to have known, bounded execution time on all requests.

In the next chapter we present a model for mixed-criticality scheduling that is suitable for high
assurance systems such as \selfour. 
